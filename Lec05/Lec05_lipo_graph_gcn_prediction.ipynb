{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Predict Lipophilicity Property Using GCN\n",
    "=====================\n",
    "\n",
    "So far, we predicted lipophilicity with linear molecular representation (fingerprint, smiles). This time, we would employ GCN architecture with graph representation.\n",
    "\n",
    "What about data?\n",
    "----------------\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CIFAR10\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Prepare Dataset and Data Loader\n",
    "----------------------------\n",
    "\n",
    "Download Lipophilicity dataset from [MoleculeNet](http://moleculenet.ai/datasets-1) Benchmark dataset.  \n",
    "You can download from the webpage or source_dataset file from the url directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q \"http://deepchem.io.s3-website-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\" -O Lipophilicity.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "\n",
    "def get_splitted_lipo_dataset(ratios=[0.8, 0.1, 0.1], seed=123):\n",
    "\n",
    "    raw_data = pd.read_csv('Lipophilicity.csv') # Open original dataset\n",
    "    smiles = raw_data['smiles']\n",
    "        \n",
    "    train_val, test = train_test_split(raw_data, test_size=ratios[2], random_state=seed)\n",
    "    train, val = train_test_split(train_val, test_size=ratios[1]/(ratios[0]+ratios[1]), random_state=seed)\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CMPD_CHEMBLID   exp                                             smiles\n",
      "1369   CHEMBL199237  2.70                 O=C(NCc1ccccn1)c2ccc(Oc3ccccc3)cc2\n",
      "3084   CHEMBL277863  2.05  COC(=O)N1CCN([C@H](CN2CCCC2)C1)C(=O)Cc3ccc(Cl)...\n",
      "2141  CHEMBL1824036 -0.51  CS(=O)(=O)c1ccc2OCC(=O)N(CCN3CCC(CC3)NCc4ccc5O...\n",
      "3741    CHEMBL87266  1.35  Cc1cc(N)c2cc(NC(=O)CC(=O)Nc3ccc4nc(C)cc(N)c4c3...\n",
      "2192   CHEMBL513370  2.36  COc1ccc(N(C(C(=O)NC[C@@H](C)O)c2ccccc2F)C(=O)c...\n",
      "...             ...   ...                                                ...\n",
      "3180   CHEMBL578061  4.06                     N(c1ccccc1)c2ccnc(Nc3ccccc3)n2\n",
      "266        CHEMBL97  2.16          COc1ccc2nccc([C@H](O)C3CC4CCN3CC4C=C)c2c1\n",
      "2398   CHEMBL138649  3.60                     Oc1ccc2OC(=CC(=O)c2c1)c3ccccc3\n",
      "2073   CHEMBL272705  2.21            C[C@H](CO)Nc1nc(SCc2occc2)nc3NC(=O)Sc13\n",
      "2480   CHEMBL177611  0.60                 Clc1ccc(cc1)C(=O)N[C@H]2CN3CCC2CC3\n",
      "\n",
      "[3359 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "datasets = get_splitted_lipo_dataset()\n",
    "smiles = datasets[0]\n",
    "print(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_SYMBOLS = ['C', 'N', 'O', 'S', 'F', 'H', 'Si', 'P', 'Cl', 'Br',\n",
    "            'Li', 'Na', 'K', 'Mg', 'Ca', 'Fe', 'As', 'Al', 'I', 'B',\n",
    "            'V', 'Tl', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
    "            'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'Mn', 'Cr', 'Pt', 'Hg', 'Pb']\n",
    "\n",
    "\n",
    "def atom_feature(atom):\n",
    "    return np.array(char_to_ix(atom.GetSymbol(), LIST_SYMBOLS) +\n",
    "                    char_to_ix(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    char_to_ix(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    char_to_ix(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    char_to_ix(int(atom.GetIsAromatic()), [0, 1]))    # (40, 6, 5, 6, 2)\n",
    "\n",
    "\n",
    "def char_to_ix(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        return [0] # Unknown Atom Token\n",
    "    return [allowable_set.index(x)+1]\n",
    "\n",
    "\n",
    "def mol2graph(smi, MAX_LEN):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "\n",
    "    X = np.zeros((MAX_LEN, 5), dtype=np.uint8)\n",
    "    A = np.zeros((MAX_LEN, MAX_LEN), dtype=np.uint8)\n",
    "\n",
    "    temp_A = Chem.rdmolops.GetAdjacencyMatrix(mol).astype(np.uint8, copy=False)[:MAX_LEN, :MAX_LEN]\n",
    "    num_atom = temp_A.shape[0]\n",
    "    A[:num_atom, :num_atom] = temp_A + np.eye(temp_A.shape[0], dtype=np.uint8)\n",
    "    \n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        feature = atom_feature(atom)\n",
    "        X[i, :] = feature\n",
    "        if i + 1 >= num_atom: break\n",
    "            \n",
    "    return X, A\n",
    "\n",
    "smiles = \"O=C(NCc1ccccn1)c2ccc(Oc3ccccc3)cc2\"\n",
    "X, A = mol2graph(smiles, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class gcnDataset(Dataset):\n",
    "    def __init__(self, df, max_len=120):\n",
    "        self.smiles = df[\"smiles\"]\n",
    "        self.exp = df[\"exp\"].values\n",
    "                \n",
    "        list_X = list()\n",
    "        list_A = list()\n",
    "        for i, smiles in enumerate(self.smiles):\n",
    "            X, A = mol2graph(smiles, max_len)\n",
    "            list_X.append(X)\n",
    "            list_A.append(A)\n",
    "            \n",
    "        self.X = np.array(list_X, dtype=np.uint8)\n",
    "        self.A = np.array(list_A, dtype=np.uint8)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.A[index], self.exp[index]\n",
    "    \n",
    "sample_dataset = gcnDataset(datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Model Architecture\n",
    "----------------------------\n",
    "\n",
    "Download Lipophilicity dataset from [MoleculeNet](http://moleculenet.ai/datasets-1) Benchmark dataset.  \n",
    "You can download from the webpage or source_dataset file from the url directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Visualization\n",
    "----------------------------\n",
    "\n",
    "Download Lipophilicity dataset from [MoleculeNet](http://moleculenet.ai/datasets-1) Benchmark dataset.  \n",
    "You can download from the webpage or source_dataset file from the url directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "def generate_setting(args, var1, var2):\n",
    "    dict_args = vars(args)\n",
    "    output = '{:92}'.format('[Exp Settings]') + '\\n'\n",
    "    output += '-'*91 + '\\n'\n",
    "\n",
    "    num_var = 3\n",
    "    cnt_var = 0\n",
    "    for keyword, value in dict_args.items():\n",
    "        if keyword != var1 and keyword != var2 and type(value) != list and not 'best' in keyword and keyword != 'elapsed':\n",
    "            str_value = str(value)\n",
    "            if str_value.isdigit():\n",
    "                if type(value) == float:\n",
    "                    temp = '| {}={:.2E}'.format(keyword, Decimal(dict_args[keyword]))\n",
    "                if type(value) == int:\n",
    "                    temp = '| {}={}'.format(keyword, str_value[:15])\n",
    "\n",
    "            else:\n",
    "                temp = '| {}={}'.format(keyword, str_value[:15])\n",
    "            output += '{:<30}'.format(temp[:30])\n",
    "            cnt_var += 1\n",
    "            if cnt_var % num_var == 0:\n",
    "                cnt_var = 0\n",
    "                output += '|\\n'\n",
    "                output += '-'*91 + '\\n'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(results, variable1, variable2, title='', filename=''):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "    fig.set_size_inches(15, 6)\n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "    sns.barplot(x=variable1, y='best_mae', hue=variable2, data=results, ax=ax[0])\n",
    "    sns.barplot(x=variable1, y='best_std', hue=variable2, data=results, ax=ax[1])\n",
    "\n",
    "    font = FontProperties()\n",
    "    font.set_family('monospace')\n",
    "    font.set_size('large')\n",
    "    alignment = {'horizontalalignment': 'center', 'verticalalignment': 'baseline'}\n",
    "    fig.text(0.5, -0.6, generate_setting(args, variable1, variable2), fontproperties=font, **alignment)\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    filename = filename if len(filename) > 0 else title\n",
    "    plt.savefig('./images/{}.png'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(results, variable1, variable2, x='true_y', y='pred_y', title='', filename='', **kwargs):\n",
    "    list_v1 = results[variable1].unique()\n",
    "    list_v2 = results[variable2].unique()\n",
    "    list_data = list()\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = results.loc[results[variable1]==value1]\n",
    "            row = row.loc[results[variable2]==value2]\n",
    "\n",
    "            best_true_y = list(row.best_true_y)[0]\n",
    "            best_pred_y = list(row.best_pred_y)[0]\n",
    "            for i in range(len(best_true_y)):\n",
    "                list_data.append({x:best_true_y[i], y:best_pred_y[i], variable1:value1, variable2:value2})\n",
    "    df = pd.DataFrame(list_data)\n",
    "\n",
    "    g = sns.FacetGrid(df, row=variable2, col=variable1, margin_titles=True)\n",
    "    g.map(plt.scatter, x, y, alpha=0.3)\n",
    "\n",
    "    def identity(**kwargs):\n",
    "        plt.plot(np.linspace(-1.5,4,50), np.linspace(-1.5,4,50),'k',linestyle='dashed')\n",
    "    g.map(identity)\n",
    "    g.set_axis_labels(x, y)\n",
    "    g.fig.suptitle(title) # can also get the figure from plt.gcf()\n",
    "    plt.subplots_adjust(top=kwargs.get('top',0.93))\n",
    "    filename = filename if len(filename) > 0 else title\n",
    "    plt.savefig('./images/{}.png'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(results, variable1, variable2, x='true_y', y='pred_y', title='', filename='', **kwargs):\n",
    "    list_v1 = results[variable1].unique()\n",
    "    list_v2 = results[variable2].unique()\n",
    "    list_data = list()\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = results.loc[results[variable1]==value1]\n",
    "            row = row.loc[results[variable2]==value2]\n",
    "\n",
    "            train_losses = list(row.train_losses)[0]\n",
    "            val_losses = list(row.val_losses)[0]\n",
    "            maes = list(row.maes)[0]\n",
    "            \n",
    "            for item in train_losses:\n",
    "                item.update({'type':'train', 'loss':item['train_loss'], variable1:value1, variable2:value2})\n",
    "                \n",
    "            for item in val_losses:\n",
    "                item.update({'type':'val', 'loss':item['val_loss'], variable1:value1, variable2:value2})\n",
    "            \n",
    "            for item in maes:\n",
    "                item.update({'type':'mae', variable1:value1, variable2:value2})\n",
    "            list_data += train_losses + val_losses + maes\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    temp_mae = df.loc[df['mae'] < df['mae'].quantile(0.98)]\n",
    "    ymax = temp_mae['mae'].max()\n",
    "    ymin = temp_mae['mae'].min()\n",
    "    \n",
    "    temp_loss = df.loc[df['loss'] < df['loss'].quantile(0.98)]\n",
    "    lossmax = temp_loss['loss'].max()\n",
    "    lossmin = temp_loss['loss'].min()\n",
    "    \n",
    "    g = sns.FacetGrid(df, row=variable2, col=variable1, hue='type', margin_titles=False)\n",
    "    axes = g.axes\n",
    "    for i in range(len(axes)):\n",
    "        for j in range(len(axes[0])):\n",
    "            if i==0:\n",
    "                g.axes[i][j].yaxis.set_label_coords(1.1,0.9)\n",
    "                \n",
    "    def mae_line(x, y, **kwargs):\n",
    "        ax2 = plt.gca().twinx()\n",
    "        ax2.plot(x, y,'g--')\n",
    "        ax2.set_ylim(kwargs['ymax']*1.05, kwargs['ymin']*0.95)\n",
    "        ax2.grid(False)\n",
    "\n",
    "    g.map(plt.plot, x, y)\n",
    "    g.map(mae_line, 'epoch', 'mae', ymin=ymin, ymax=ymax)\n",
    "    g.set_axis_labels(x, y)\n",
    "    g.fig.suptitle(title) # can also get the figure from plt.gcf()\n",
    "    g.add_legend()\n",
    "    \n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_ylim(lossmin, lossmax)\n",
    "        \n",
    "    plt.subplots_adjust(top=kwargs.get('top', 0.93))\n",
    "    filename = filename if len(filename) > 0 else title\n",
    "    plt.savefig('./images/{}.png'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Experiment\n",
    "----------------------------\n",
    "\n",
    "Download Lipophilicity dataset from [MoleculeNet](http://moleculenet.ai/datasets-1) Benchmark dataset.  \n",
    "You can download from the webpage or source_dataset file from the url directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "\n",
    "#===== Activation =====#\n",
    "def gelu(x):\n",
    "\n",
    "    \"\"\" Ref: https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py\n",
    "        Implementation of the gelu activation function.\n",
    "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
    "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \"\"\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu}\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_attn_head, dropout=0.1):\n",
    "        super(Attention, self).__init__()   \n",
    "\n",
    "        self.num_attn_heads = num_attn_head\n",
    "        self.attn_dim = output_dim // num_attn_head\n",
    "        self.projection = nn.ModuleList([nn.Linear(input_dim, self.attn_dim) for i in range(self.num_attn_heads)])\n",
    "        self.coef_matrix = nn.ParameterList([nn.Parameter(torch.FloatTensor(self.attn_dim, self.attn_dim)) for i in range(self.num_attn_heads)])\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.param_initializer()\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        list_X_head = list()\n",
    "        for i in range(self.num_attn_heads):\n",
    "            X_projected = self.projection[i](X)\n",
    "            attn_matrix = self.attn_coeff(X_projected, A, self.coef_matrix[i])\n",
    "            X_head = torch.matmul(attn_matrix, X_projected)\n",
    "            list_X_head.append(X_head)\n",
    "            \n",
    "        X = torch.cat(list_X_head, dim=2)\n",
    "        X = self.relu(X)\n",
    "        return X\n",
    "            \n",
    "    def attn_coeff(self, X_projected, A, C):\n",
    "        X = torch.einsum('akj,ij->aki', (X_projected, C))\n",
    "        attn_matrix = torch.matmul(X, torch.transpose(X_projected, 1, 2)) \n",
    "        attn_matrix = torch.mul(A, attn_matrix)\n",
    "        attn_matrix = self.dropout(self.tanh(attn_matrix))\n",
    "        return attn_matrix\n",
    "    \n",
    "    def param_initializer(self):\n",
    "        for i in range(self.num_attn_heads):    \n",
    "            nn.init.xavier_normal_(self.projection[i].weight.data)\n",
    "            nn.init.xavier_normal_(self.coef_matrix[i].data)\n",
    "\n",
    "\n",
    "#####################################################\n",
    "# ===== Gconv, Readout, BN1D, ResBlock, Encoder =====#\n",
    "#####################################################\n",
    "\n",
    "class GConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, attn):\n",
    "        super(GConv, self).__init__()\n",
    "        self.attn = attn\n",
    "        if self.attn is None:\n",
    "            self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, X, A):\n",
    "        if self.attn is None:\n",
    "            x = self.fc(X)\n",
    "            x = torch.matmul(A, x)\n",
    "        else:\n",
    "            x = self.attn(X, A)            \n",
    "        return x, A\n",
    "    \n",
    "class BN1d(nn.Module):\n",
    "    def __init__(self, out_dim, use_bn):\n",
    "        super(BN1d, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "             \n",
    "    def forward(self, x):\n",
    "        if not self.use_bn:\n",
    "            return  x\n",
    "        origin_shape = x.shape\n",
    "        x = x.view(-1, origin_shape[-1])\n",
    "        x = self.bn(x)\n",
    "        x = x.view(origin_shape)\n",
    "        return x\n",
    "        \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, use_bn, use_attn, dp_rate, sc_type, n_attn_head=None):\n",
    "        super(ResBlock, self).__init__()   \n",
    "        self.use_bn = use_bn\n",
    "        self.sc_type = sc_type\n",
    "        \n",
    "        attn = Attention(in_dim, out_dim, n_attn_head) if use_attn else None\n",
    "        self.gconv = GConv(in_dim, out_dim, attn)\n",
    "        \n",
    "        self.bn1 = BN1d(out_dim, use_bn)\n",
    "        self.dropout = nn.Dropout2d(p=dp_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if not self.sc_type in ['no', 'gsc', 'sc']:\n",
    "            raise Exception\n",
    "\n",
    "        if self.sc_type != 'no':\n",
    "            self.bn2 = BN1d(out_dim, use_bn)\n",
    "            self.shortcut = nn.Sequential()\n",
    "            if in_dim != out_dim:\n",
    "                self.shortcut.add_module('shortcut', nn.Linear(in_dim, out_dim, bias=False))\n",
    "                \n",
    "        if self.sc_type == 'gsc':\n",
    "            self.g_fc1 = nn.Linear(out_dim, out_dim, bias=True)\n",
    "            self.g_fc2 = nn.Linear(out_dim, out_dim, bias=True)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, _x, A):\n",
    "        x, A = self.gconv(_x, A)\n",
    "\n",
    "        if self.sc_type == 'no': #no skip-connection\n",
    "            x = self.relu(self.bn1(x))\n",
    "            return self.dropout(x), A\n",
    "        \n",
    "        elif self.sc_type == 'sc': # basic skip-connection\n",
    "            x = self.relu(self.bn1(x))\n",
    "            x = x + self.shortcut(_x)          \n",
    "            return self.dropout(self.relu(self.bn2(x))), A\n",
    "        \n",
    "        elif self.sc_type == 'gsc': # gated skip-connection\n",
    "            x = self.relu(self.bn1(x)) \n",
    "            x1 = self.g_fc1(self.shortcut(_x))\n",
    "            x2 = self.g_fc2(x)\n",
    "            gate_coef = self.sigmoid(x1+x2)\n",
    "            x = torch.mul(x1, gate_coef) + torch.mul(x2, 1.0-gate_coef)\n",
    "            return self.dropout(self.relu(self.bn2(x))), A\n",
    "             \n",
    "class Readout(nn.Module):\n",
    "    def __init__(self, out_dim, molvec_dim):\n",
    "        super(Readout, self).__init__()\n",
    "        self.readout_fc = nn.Linear(out_dim, molvec_dim)\n",
    "        nn.init.xavier_normal_(self.readout_fc.weight.data)\n",
    "\n",
    "    def forward(self, output_H):\n",
    "        molvec = self.readout_fc(output_H)\n",
    "        molvec = torch.mean(molvec, dim=1)\n",
    "        return molvec\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Net, self).__init__()   \n",
    "        \n",
    "        # Create Atom Element embedding layer\n",
    "        self.embedding = self.create_emb_layer([args.vocab_size, args.degree_size,\n",
    "                                                args.numH_size, args.valence_size,\n",
    "                                                args.isarom_size],  args.emb_train)        \n",
    "        # Create Residual Convolution layer\n",
    "        self.gconvs = nn.ModuleList()\n",
    "        for i in range(args.n_layer):\n",
    "            if i==0:\n",
    "                self.gconvs.append(ResBlock(args.in_dim, args.out_dim, args.use_bn, False, args.dp_rate, args.sc_type))\n",
    "            else:\n",
    "                self.gconvs.append(ResBlock(args.out_dim, args.out_dim, args.use_bn, args.use_attn, args.dp_rate, args.sc_type, args.n_attn_head))\n",
    "\n",
    "        self.readout = Readout(args.out_dim, args.molvec_dim)\n",
    "\n",
    "        # Create MLP layers for regression\n",
    "        self.fc1 = nn.Linear(args.molvec_dim, args.molvec_dim//2)\n",
    "        self.fc2 = nn.Linear(args.molvec_dim//2, 1)\n",
    "        self.bn1 = BN1d(args.molvec_dim//2, args.use_bn)\n",
    "        self.act = ACT2FN[args.act]\n",
    "        self.dropout = nn.Dropout(p=args.dp_rate)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def create_emb_layer(self, list_vocab_size, emb_train=False):\n",
    "        list_emb_layer = nn.ModuleList()\n",
    "        for i, vocab_size in enumerate(list_vocab_size):\n",
    "            vocab_size += 1\n",
    "            emb_layer = nn.Embedding(vocab_size, vocab_size)\n",
    "            weight_matrix = torch.zeros((vocab_size, vocab_size))\n",
    "            for i in range(vocab_size):\n",
    "                weight_matrix[i][i] = 1\n",
    "            emb_layer.load_state_dict({'weight': weight_matrix})\n",
    "            emb_layer.weight.requires_grad = emb_train\n",
    "            list_emb_layer.append(emb_layer)\n",
    "        return list_emb_layer\n",
    "\n",
    "          \n",
    "    def _embed(self, x):\n",
    "        list_embed = list()\n",
    "        for i in range(5):\n",
    "            list_embed.append(self.embedding[i](x[:, :, i]))\n",
    "        x = torch.cat(list_embed, 2)\n",
    "        return x\n",
    "    \n",
    "    def _encode(self, x, A):\n",
    "        for i, module in enumerate(self.gconvs):\n",
    "            x, A = module(x, A)\n",
    "        molvec = self.readout(x)\n",
    "        return molvec\n",
    "    \n",
    "    def forward(self, x, A):\n",
    "        A = A.float()\n",
    "        x = self._embed(x)          # embedding layer\n",
    "        molvec = self._encode(x, A)   # encoding through gcn layer\n",
    "        molvec = self.dropout(self.bn1(self.act(self.fc1(molvec))))\n",
    "        molvec = self.fc2(molvec)\n",
    "        \n",
    "        return torch.squeeze(molvec)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, args, **kwargs):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    list_train_loss = list()\n",
    "    cnt_iter = 0\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X, A, y = batch[0].long(), batch[1].long(), batch[2].float()\n",
    "        X, A, y = X.to(args.device), A.to(args.device), y.to(args.device)\n",
    "    \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_y = model(X, A)\n",
    "        \n",
    "        train_loss = criterion(pred_y, y)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        list_train_loss.append({'epoch':batch_idx/len(dataloader)+kwargs['epoch'], 'train_loss':train_loss.item()})\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cnt_iter += 1\n",
    "    return model, list_train_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, args):\n",
    "    \n",
    "    epoch_val_loss = 0\n",
    "    cnt_iter = 0\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X, y = batch[0].long(), batch[1].float()\n",
    "        X, y = X.to(args.device), y.to(args.device)\n",
    "    \n",
    "        model.eval()\n",
    "        pred_y = model(X)\n",
    "        val_loss = criterion(pred_y, y)\n",
    "        epoch_val_loss += val_loss.item()\n",
    "        cnt_iter += 1\n",
    "\n",
    "    return epoch_val_loss/cnt_iter\n",
    "\n",
    "def test(model, dataloader, args, **kwargs):\n",
    "\n",
    "    list_y, list_pred_y = list(), list()\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X, y = batch[0].long(), batch[1].float()\n",
    "        X, y = X.to(args.device), y.to(args.device)\n",
    "    \n",
    "        model.eval()\n",
    "        pred_y = model(X)\n",
    "        list_y += y.cpu().detach().numpy().tolist()\n",
    "        list_pred_y += pred_y.cpu().detach().numpy().tolist()\n",
    "\n",
    "    mae = mean_absolute_error(list_y, list_pred_y)\n",
    "    std = np.std(np.array(list_y)-np.array(list_pred_y))\n",
    "    return mae, std, list_y, list_pred_y\n",
    "\n",
    "\n",
    "def experiment(partition, args):\n",
    "    ts = time.time()\n",
    "    args.input_shape = (args.max_len, args.vocab_size)\n",
    "    \n",
    "    model = Net(args)\n",
    "    \n",
    "    model.to(args.device)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Initialize Optimizer\n",
    "    trainable_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    if args.optim == 'ADAM':\n",
    "        optimizer = optim.Adam(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSProp':\n",
    "        optimizer = optim.RMSprop(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, \"Undefined Optimizer Type\"\n",
    "        \n",
    "    # Train, Validate, Evaluate\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "    list_mae = list()\n",
    "    list_std = list()\n",
    "    \n",
    "    args.best_mae = 10000\n",
    "    for epoch in range(args.epoch):\n",
    "        model, train_losses = train(model, partition['train'], optimizer, criterion, args, **{'epoch':epoch})\n",
    "        val_loss = validate(model, partition['val'], criterion, args)\n",
    "        mae, std, true_y, pred_y = test(model, partition['test'], args, **{'epoch':epoch})\n",
    "        \n",
    "        list_train_loss += train_losses\n",
    "        list_val_loss.append({'epoch':epoch, 'val_loss':val_loss})\n",
    "        list_mae.append({'epoch':epoch, 'mae':mae})\n",
    "        list_std.append({'epoch':epoch, 'std':std})\n",
    "        \n",
    "        if args.best_mae > mae or epoch==0:\n",
    "            args.best_epoch = epoch\n",
    "            args.best_mae = mae\n",
    "            args.best_std = std\n",
    "            args.best_true_y = true_y\n",
    "            args.best_pred_y = pred_y\n",
    "            \n",
    "\n",
    "    # End of experiments\n",
    "    te = time.time()\n",
    "    args.elapsed = te-ts\n",
    "    args.train_losses = list_train_loss\n",
    "    args.val_losses = list_val_loss\n",
    "    args.maes = list_mae\n",
    "    args.stds = list_std\n",
    "\n",
    "    return model, args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [17920 x 65], m2: [59 x 256] at /opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-5cbc38050c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-153505e0bc26>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(partition, args)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-153505e0bc26>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-ffb563c886de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, A)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mmolvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# encoding through gcn layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mmolvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mmolvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-ffb563c886de>\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(self, x, A)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mmolvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmolvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-ffb563c886de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, _x, A)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#no skip-connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-ffb563c886de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, A)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [17920 x 65], m2: [59 x 256] at /opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from utils import *\n",
    "\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# ==== Embedding Config ==== #\n",
    "args.max_len = 70\n",
    "args.vocab_size = 41\n",
    "args.degree_size = 6\n",
    "args.numH_size = 5\n",
    "args.valence_size = 6\n",
    "args.isarom_size = 2\n",
    "args.emb_train = False\n",
    "\n",
    "\n",
    "# ==== Model Architecture Config ==== #\n",
    "args.in_dim = 59\n",
    "args.out_dim = 256\n",
    "args.molvec_dim = 512\n",
    "args.n_layer = 4\n",
    "args.n_attn_head = 8\n",
    "args.sc_type = 'sc'\n",
    "args.use_attn = True\n",
    "args.use_bn = True\n",
    "args.act = 'relu'\n",
    "args.dp_rate = 0.3\n",
    "\n",
    "\n",
    "# ==== Optimizer Config\n",
    "args.lr = 0.00005\n",
    "args.l2_coef = 0.0001\n",
    "args.optim = 'ADAM'\n",
    "\n",
    "\n",
    "# ==== Training Config ==== #\n",
    "args.epoch = 100\n",
    "args.batch_size = 256\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.exp_name = 'exp1_lr_stage'\n",
    "\n",
    "\n",
    "writer = Writer(prior_keyword=['n_layer', 'use_bn', 'lr', 'dp_rate', 'emb_train', 'epoch', 'batch_size'])\n",
    "writer.clear()\n",
    "\n",
    "# Define Hyperparameter Search Space\n",
    "#list_n_layer = [1]\n",
    "list_lr = [0.005]\n",
    "list_n_layer = [3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(gcnDataset(datasets[0], args.max_len), batch_size=args.batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(gcnDataset(datasets[1], args.max_len), batch_size=args.batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(gcnDataset(datasets[2], args.max_len), batch_size=args.batch_size, shuffle=False)\n",
    "partition = {'train': train_dataloader, 'val': val_dataloader, 'test': test_dataloader}\n",
    "\n",
    "cnt_exp = 0\n",
    "for lr in list_lr:\n",
    "    for n_layer in list_n_layer:\n",
    "        args.lr = lr\n",
    "        args.n_layer = n_layer\n",
    "\n",
    "        model, result = experiment(partition, args)\n",
    "        writer.write(result)\n",
    "        \n",
    "        cnt_exp += 1\n",
    "        print('[Exp {:2}] got mae: {:2.3f}, std: {:2.3f} at epoch {:2}'.format(cnt_exp, result.best_mae, result.best_std, result.best_epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "\n",
    "results = writer.read(exp_name='exp1_lr_stage')\n",
    "#results = results.loc[results['epoch']==50]\n",
    "variable1 = 'n_stage'\n",
    "variable2 = 'lr'\n",
    "\n",
    "\n",
    "plot_performance(results, variable1, variable2,\n",
    "                'Performance depends on {} vs {}'.format(variable1, variable2),\n",
    "                'exp1_Performance {} vs {}'.format(variable1, variable2))\n",
    "\n",
    "plot_distribution(results, variable1, variable2, 'true_y', 'pred_y', \n",
    "                  'Prediction results depends on {} vs {}'.format(variable1, variable2),\n",
    "                  'exp1_Prediction {} vs {}'.format(variable1, variable2))\n",
    "\n",
    "plot_loss(results, variable1, variable2, 'epoch', 'loss', \n",
    "                  'Loss depends on {} vs {}'.format(variable1, variable2),\n",
    "                  'exp1_Loss {} vs {}'.format(variable1, variable2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "build_central"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
